{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Python for Data Science Weeks 1-12: Final Assignment\n",
                "\n",
                "**_Author: Carleton L. Smith_**\n",
                "\n",
                "**Expected time = 3 hrs**\n",
                "\n",
                "**Total Points = 105**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "    \n",
                "## Assignment Overview\n",
                "\n",
                "The following activity is a comprehensive assignment assessing your capability across the key areas covered in Python for Data Science. Completing this assignment will demonstrate your proficiency in basic Python operations as well as more advanced activities such as data cleaning, exploratory data analysis, and linear algebra for machine learning. This is a graded, required assignment. Those who score 75% or higher can be confident in their proficiency. \n",
                "\n",
                "This assignment is designed to build your familiarity and comfort coding in Python while also helping you review key topics from each module. As you progress through the assignment, answers will get increasingly complex. It is important that you adopt a data scientist's mindset when completing this assignment. **Remember to run your code from each cell before submitting your assignment.** Running your code beforehand will notify you of errors and give you a chance to fix your errors before submitting. You should view your Vocareum submission as if you are delivering a final project to your manager or client.\n",
                "\n",
                "\n",
                "***Vocareum Tips***\n",
                "- Do not add arguments or options to functions unless you are specifically asked to. This will cause an error in Vocareum.\n",
                "- Do not use a library unless you are expicitly asked to in the question. \n",
                "- You can download the Grading Report after submitting the assignment. This will include feedback and hints on incorrect questions. \n",
                "\n",
                "\n",
                "### Learning Objectives\n",
                "\n",
                "Passing this assignment will demonstrate your ability to:\n",
                "- Work with native Python types and data structures\n",
                "- Use built-in and create user-defined functions\n",
                "- Prepare a dataset for exploratory data analysis and modeling\n",
                "- Manipulate and explore data stored in pandas DataFrames\n",
                "- Implement advanced linear algebra techniques using scikit-learn\n",
                "- Create a simple model using Ordinary Least Squares method"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Index:\n",
                "\n",
                "#### Data Types and Functions Python:\n",
                "\n",
                "- [Question 1](#Question-1)\n",
                "- [Question 2](#Question-2)\n",
                "- [Question 3](#Question-3)\n",
                "- [Question 4](#Question-4)\n",
                "- [Question 5](#Question-5)\n",
                "- [Question 6](#Question-6)\n",
                "\n",
                "#### Preprocessing Data\n",
                "- [Question 7](#Question-7)\n",
                "- [Question 8](#Question-8)\n",
                "- [Question 9](#Question-9)\n",
                "- [Question 10](#Question-10)\n",
                "- [Question 11](#Question-11)\n",
                "- [Question 12](#Question-12)\n",
                "- [Question 13](#Question-13)\n",
                "\n",
                "#### Exploratory Data Analysis\n",
                "- [Question 14](#Question-14)\n",
                "- [Question 15](#Question-15)\n",
                "- [Question 16](#Question-16)\n",
                "\n",
                "####  Linear Algebra and Ordinary Least Squares\n",
                "- [Question 17](#Question-17)\n",
                "- [Question 18](#Question-18)\n",
                "- [Question 19](#Question-19)\n",
                "- [Question 20](#Question-20)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Python for Data Science Weeks 1-12: Final Assignment Summary\n",
                "\n",
                "This assignment is broken into 4 parts:\n",
                "\n",
                "1. Data Types and Functions\n",
                "2. Preprocessing Data (Cleaning Data)\n",
                "3. Exploratory Data Analysis (EDA)\n",
                "4. Linear Algebra and Ordinary Least Squares (OLS)\n",
                "\n",
                "The first section will test you ability to create functions and work with data structures. In the second section, a dataset is intoduced and you will be asked a series of data cleaning questions. The third section includes questions about exploring this dataset. Finally, the last section tasks you with performing advanced linear algebra techniques and modeling with linear regression.\n",
                "\n",
                "Run the `Imports` and `Constants` cells prior to answering questions."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import pickle\n",
                "import inspect\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.decomposition import PCA\n",
                "import statsmodels.api as sm\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Constants"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "BANK_DATA_PATH = '.\/data\/bank_prepared.csv'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Types and Functions Python:\n",
                "\n",
                "This section will test your ability to work with Python data types and built-in functions. You will also be asked to create user-defined functions for specific tasks."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 1\n",
                "\n",
                "*2 Points*\n",
                "\n",
                "Consider the string below assigned to `beatles_album`. Your task is to invoke the appropriate [string method](https:\/\/docs.python.org\/3.7\/library\/string.html) on `beatles_album` so that a list is returned. Every element in the returned list should be an individual word from `beatles_album`.\n",
                "\n",
                "Assign the returned list to `ans1`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "beatles_album = \"Sgt. Pepper's Lonely Hearts Club Band\"\n",
                "print(beatles_album)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### GRADED\n",
                "beatles_album = \"Sgt. Pepper's Lonely Hearts Club Band\"\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "ans1 = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n",
                "\n",
                "### For verifying answer:\n",
                "test_string = 'John Paul George Ringo'\n",
                "test_output = ['John', 'Paul', 'George', 'Ringo']\n",
                "print(\"Test string:\\t'{}'\".format(test_string))\n",
                "print('Test output:\\t{}'.format(test_output))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 01",
                    "locked": true,
                    "points": "2",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 2\n",
                "\n",
                "*2 Points*\n",
                "\n",
                "This question consists of two parts:\n",
                "\n",
                "1. Cast the tuple below named `beatles_tuple` to a list and assign to the variable to `beatles_list`\n",
                "2. Append the string \"Let It Be\" to the end of the `beatles_list`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "beatles_tuple = (\n",
                "    \"Please Please Me\",\n",
                "    \"With The Beatles\",\n",
                "    \"A Hard Day's Night\",\n",
                "    \"Beatles For Sale\",\n",
                "    \"Help!\",\n",
                "    \"Rubber Soul\",\n",
                "    \"Revolver\",\n",
                "    \"Sgt. Pepper's Lonely Hearts Club Band\",\n",
                "    \"The Beatles (White Album)\",\n",
                "    \"Yellow Submarine\",\n",
                "    \"Abbey Road\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "beatles_list = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n",
                "\n",
                "### For verifying answer:\n",
                "print(\"'beatles_list' type:\\t{}\".format(type(beatles_list)))\n",
                "print(\"Your last item:\\t\\t{}\".format(beatles_list[-1]))\n",
                "print(\"Expected last item:\\t{}\".format(\"Let It Be\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 02",
                    "locked": true,
                    "points": "2",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 3\n",
                "\n",
                "*4 Points*\n",
                "\n",
                "The dictionary `beatles` below is a data structure that stores which band member contributed as a songwriter to the songs on their albums ([see source credit](#beatles)).\n",
                "\n",
                "Your task for this question is to extract out the list of songs that John Lennon (\"Lennon\") wrote on the album *Abbey Road*. Assign the answer as a list to the variable `lennon_abbey_road`.\n",
                "\n",
                "Here's a sample of the structure: \n",
                "\n",
                "```\n",
                "{\n",
                "    'Anthology 2': [{\n",
                "        'Lennon': ['12-Bar Original', \"If You've Got Trouble\", 'Real Love'],\n",
                "        'McCartney': ['12-Bar Original',\"If You've Got Trouble\",'Real Love','That Means a Lot'],\n",
                "        'Harrison': ['12-Bar Original', 'Real Love'],\n",
                "        'Starkey': ['12-Bar Original', 'Real Love']\n",
                "        }],\n",
                "        \n",
                "    ...,\n",
                "    \n",
                "    'Rubber Soul': [{\n",
                "        'Lennon': [\n",
                "            'Girl', 'In My Life', 'Michelle', 'Norwegian Wood (This Bird Has Flown)',\n",
                "            'Run for Your Life','The Word','Wait'\n",
                "            ],\n",
                "        'McCartney': [\n",
                "            \"I'm Looking Through You\", 'In My Life', 'Michelle', 'Norwegian Wood (This Bird Has Flown)',\n",
                "            'Run for Your Life', 'The Word', 'Wait', \"You Won't See Me\"\n",
                "            ],\n",
                "        'Harrison': ['Think for Yourself'],\n",
                "        'Starkey': []\n",
                "    }]\n",
                "}\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "# read beatles data as dictionary\n",
                "def read_beatles():\n",
                "    HEADER = ['title', 'year', 'album', 'songwriter',]\n",
                "    beats = pd.read_csv(\n",
                "        '.\/data\/songs.tsv',\n",
                "        delimiter='\\t',\n",
                "        header=None,\n",
                "        usecols=[0,1,2,3],\n",
                "        names=HEADER\n",
                "    )\n",
                "    beats = beats.dropna()\n",
                "\n",
                "    beats['to_drop'] = beats['album'].apply(lambda x: False if x[0:3] == 'UK:' else True)\n",
                "    beats = beats[beats['to_drop']]\n",
                "    beats = beats.drop('to_drop', axis=1)\n",
                "    to_drop_albs = beats['album'].value_counts()[beats['album'].value_counts() <= 2].index.tolist()\n",
                "    beats['to_drop'] = beats['album'].isin(to_drop_albs)\n",
                "    beats = beats[~beats['to_drop']]\n",
                "    beats = beats.drop('to_drop', axis=1)\n",
                "\n",
                "    beatles_dict = dict()\n",
                "    members = ['Lennon','McCartney','Harrison', 'Starkey']\n",
                "    for idx in beats.index:\n",
                "        alb = beats.loc[idx,'album']\n",
                "        if not beatles_dict.get(alb):  # check if album already in there\n",
                "            # set up album dictionary\n",
                "            inner_dict = {m:list() for m in members}\n",
                "            beatles_dict.update({alb: inner_dict})\n",
                "        title = beats.loc[idx, 'title']\n",
                "        writer = beats.loc[idx, 'songwriter']\n",
                "        for member in members:\n",
                "            if member in writer:\n",
                "                beatles_dict[alb][member].append(title)\n",
                "    # beatles_dict = pd.read_csv(\n",
                "    #     '.\/datasets\/beatles.csv',\n",
                "    #     index_col='album'\n",
                "    #     ).to_dict(orient='index')\n",
                "    beatles_dict = {key:[beatles_dict[key]] for key in beatles_dict}\n",
                "    return beatles_dict\n",
                "\n",
                "\n",
                "beatles = read_beatles()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "# Extract out the list of songs that John Lennon (\"Lennon\") \n",
                "# wrote on the album \"Abbey Road\".\n",
                "# Assign answer as a list to the variable `lennon_abbey_road`.\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "lennon_abbey_road = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 03",
                    "locked": true,
                    "points": "4",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 4\n",
                "\n",
                "*5 Points*\n",
                "\n",
                "According to the `beatles` dictionary, how many total combined songs did George Harrison (\"Harrison\") and Ringo Starr (\"Starkey\") contribute to on the *Magical Mystery Tour* and *Revolver* albums? Assign the answer to `ringo_harrison_songs` as an integer or float. \n",
                "\n",
                "Hint: You may find some of Python's [built-in functions](https:\/\/docs.python.org\/3\/library\/functions.html) helpful for this exercise."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "ringo_harrison_songs = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 04",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 5\n",
                "\n",
                "*5 Points*\n",
                "\n",
                "Create a function called `dictionary_builder` that accepts 2 parameters and returns a dictionary, where the keys are strings from the parameter `col_names` and the values are the respective list from `list_of_lists`:\n",
                "\n",
                "    Parameters:\n",
                "    list_of_lists -- a list of elements, which themselves are lists.\n",
                "    col_names -- list of strings; the name label for each respective list inside of `list_of_lists`\n",
                "    \n",
                "    Returns: dict; a dictionary with column names as keys and corresponding list as the value.\n",
                "    \n",
                "    Example:\n",
                "    \n",
                "    >>> col_names = ['col_1', 'col_2', 'col_3',]\n",
                "    >>> list_of_lists = [\n",
                "            [ 0,  1,  2,  3,  4],\n",
                "            [ 5,  6,  7,  8,  9],\n",
                "            [10, 11, 12, 13, 14],\n",
                "        ]\n",
                "    \n",
                "    >>> dictionary_builder(list_of_lists, col_names)\n",
                "        {'col_1': [0, 1, 2, 3, 4],\n",
                "         'col_2': [5, 6, 7, 8, 9],\n",
                "         'col_3': [10, 11, 12, 13, 14]}\n",
                "    \n",
                "    Hint: To iterate through two objects at once, see the built-in `zip()` function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "def dictionary_builder(list_of_lists, col_names):\n",
                "    pass\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n",
                "\n",
                "### For verifying answer\n",
                "sample_names = ['col_1', 'col_2', 'col_3',]\n",
                "sample_lst = [\n",
                "    [ 0,  1,  2,  3,  4],\n",
                "    [ 5,  6,  7,  8,  9],\n",
                "    [10, 11, 12, 13, 14],\n",
                "]\n",
                "result = {\n",
                "    'col_1': [0, 1, 2, 3, 4],\n",
                "    'col_2': [5, 6, 7, 8, 9],\n",
                "    'col_3': [10, 11, 12, 13, 14]\n",
                "}\n",
                "print(\"Your result:\\t\\t{}\".format(dictionary_builder(sample_lst, sample_names)))\n",
                "print(\"Expected result:\\t{}\".format(result))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 05",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Note on Dictionaries and Dataframes\n",
                "Several questions above required you to work with dictionaries. This is because dictionaries are a convenient data structure to store data in Python. In addition to their performance benefits, they're also easily converted to pandas dataframe objects."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sample_dict = {\n",
                "    'col_1': [0, 1, 2, 3, 4],\n",
                "    'col_2': [5, 6, 7, 8, 9],\n",
                "    'col_3': [10, 11, 12, 13, 14]\n",
                "}\n",
                "print(sample_dict)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This can be converted to a dataframe in one line:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.DataFrame(sample_dict)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Alternatively:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.DataFrame().from_dict(sample_dict)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 6\n",
                "\n",
                "*2 Points*\n",
                "\n",
                "Create a function that accepts two parameters: a pandas dataframe and a list of column names. The function should return a new dataframe that contains only the columns listed in `col_names`.\n",
                "\n",
                "    Parameters:\n",
                "    df -- a pandas DataFrame\n",
                "    col_names -- list; a list of column names from df\n",
                "    \n",
                "    Returns: pandas DataFrame; a subset of df with only columns listed in col_names\n",
                "    \n",
                "    Example:\n",
                "    \n",
                "    >>> data_dict = {\n",
                "            'numbers': [1, 2, 3],\n",
                "            'colors': ['red', 'green', 'blue'],\n",
                "            'letters': ['a', 'b', 'c'],\n",
                "        }\n",
                "    >>> df = pd.DataFrame(data_dict)\n",
                "    >>> col_names = ['numbers', 'letters']\n",
                "    >>> df_subset(df, col_names)\n",
                "       numbers letters\n",
                "    0        1       a\n",
                "    1        2       b\n",
                "    2        3       c"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "def df_subset(df, col_names):\n",
                "    pass\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n",
                "\n",
                "### For verifying answer:\n",
                "data_dict = {\n",
                "    'numbers': [1, 2, 3],\n",
                "    'colors': ['red', 'green', 'blue'],\n",
                "    'letters': ['a', 'b', 'c'],\n",
                "}\n",
                "sample_df = pd.DataFrame(data_dict)\n",
                "sample_cols = ['numbers', 'letters']\n",
                "result = pd.DataFrame(\n",
                "    {'numbers': [1, 2, 3],\n",
                "    'letters': ['a', 'b', 'c'],}\n",
                ")\n",
                "print(\"Your result:\")\n",
                "print(df_subset(sample_df, sample_cols))\n",
                "print()\n",
                "print(\"Expected result:\")\n",
                "print(result)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 06",
                    "locked": true,
                    "points": "2",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Preprocessing Data\n",
                "\n",
                "This section will focus on preprocessing (cleaning) data. For this, we will use the sample dataset `bank` below, which contains data from marketing phone calls made on behalf of a bank. The version of the `bank` dataset we are using is partially preprocessed. You can find the raw data and column descriptions in the [UCI Machine Learning Repository](https:\/\/archive.ics.uci.edu\/ml\/datasets\/Bank+Marketing)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "bank = pd.read_csv(BANK_DATA_PATH)\n",
                "bank.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Data Dictionary\n",
                "\n",
                "```\n",
                "##### Input Attributes\n",
                "\n",
                "age       : client age (numeric)\n",
                "job       : type of job (categorical)\n",
                "marital   : marital status (categorical)\n",
                "education : highest level of client's education (categorical)\n",
                "default   : has credit in default? (categorical)\n",
                "balance   : the account balance of the client (numeric)\n",
                "housing   : has housing loan? (categorical)\n",
                "loan      : has personal loan? (categorical)\n",
                "\n",
                "##### Other Attributes\n",
                "\n",
                "campaign  : number of contacts performed during this campaign and for this client (numeric)\n",
                "pdays     : # of days after client was last contacted from a previous campaign (numeric; -1 means no previous contact)\n",
                "previous  : number of contacts performed before this campaign and for this client (numeric)\n",
                "poutcome  : outcome of the previous marketing campaign (categorical)\n",
                "\n",
                "##### Related with the last contact of the current campaign\n",
                "\n",
                "contact   : contact communication type (categorical)\n",
                "month     : last contact month of year (categorical)\n",
                "day       : day of the month (categorical)\n",
                "*duration : last contact duration, in seconds (numeric)\n",
                "\n",
                "#### Target Variable\n",
                "y         : has the client subscribed a term deposit? (binary: 'yes','no')\n",
                "\n",
                "\n",
                "```\n",
                "\n",
                "*__Important note__: the `duration` attribute highly affects the output target (e.g., if `duration`=0 then `y`='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call `y` is known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 7\n",
                "\n",
                "*2 Points*\n",
                "\n",
                "First, let's rename the columns to be more descriptive. Rename the columns of `bank` to the names stored in the list called `NEW_COL_NAMES` below. Assign the dataframe with renamed columns to the variable `bank_renamed`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "NEW_COL_NAMES = {\n",
                "    'marital': 'marital_status',\n",
                "    'default': 'has_credit_default',\n",
                "    'balance': 'account_balance',\n",
                "    'housing': 'has_housing_loan',\n",
                "    'loan': 'has_personal_loan',\n",
                "    'contact': 'contact_type',\n",
                "    'day': 'day_of_month',\n",
                "    'duration': 'last_contact_duration',\n",
                "    'campaign': 'num_contacts_campaign',\n",
                "    'pdays': 'days_since_prev_campaign',\n",
                "    'previous': 'num_contacts_previous',\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "bank_renamed = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 07",
                    "locked": true,
                    "points": "2",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's reload the data with the new column names. Next, we will separate the target variable (`y`) from the features. We will assign the features to `X` and the target to the variable `y`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "# make list of new columns\n",
                "col_lst = [\n",
                "    'age', 'job', 'marital_status', 'education',\n",
                "    'has_credit_default', 'account_balance', 'has_housing_loan',\n",
                "    'has_personal_loan', 'contact_type', 'day_of_month',\n",
                "    'month', 'last_contact_duration', 'num_contacts_campaign',\n",
                "    'days_since_prev_campaign', 'num_contacts_previous',\n",
                "    'poutcome', 'y',\n",
                "]\n",
                "# reload data\n",
                "bank_renamed = pd.read_csv(BANK_DATA_PATH, header=0, names=col_lst)\n",
                "# separate X and y\n",
                "X = bank_renamed.drop('y', axis=1)\n",
                "y = bank_renamed['y']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "#### Note on our target variable:\n",
                ">Later in this assignment, you will be asked to build regression models. For those exercises, we will treat `account_balance` as the target variable because it is a continuous variable (`y` is discrete). Despite this, the following preprocessing exercises will consider `y` the target variable simply because this approach pedagogically lends itself well to testing common preprocessing tasks.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 8\n",
                "\n",
                "*10 Points*\n",
                "\n",
                "Before preparing your data for modeling, you should partition your dataset into training and testing sets. You should do this before making any changes so that you will have a valid set of untouched samples to test the models you make later. This is a standard practice. Using `sklearn`'s [StratifiedShuffleSplit](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.StratifiedShuffleSplit.html) class, we will randomly partition 35% of the data into testing and the rest into training.\n",
                "\n",
                "The first 5 steps in this process are provided below. You are expected to complete steps 6 and 7 on your own.\n",
                "\n",
                ">Hint: This is covered in Week 8 (Sampling).\n",
                "\n",
                "**Steps:**\n",
                "\n",
                "1.  Instantiate an instance of StratifiedShuffleSplit with the following signature and assign to variable `sss`. Set the `random_state` to `42` for reproducibility:\n",
                ">`sss = StratifiedShuffleSplit(n_splits=1, test_size=0.35, random_state=42)`\n",
                "\n",
                "2. Use the `.split()` method to generate indices for splitting data. Assign the output to the variable `indices_gen`. The output of `sss.split()` is a generator object (similar to what `range()` produces). Read more about them [here](https:\/\/realpython.com\/introduction-to-python-generators\/) and [here](https:\/\/www.dataquest.io\/blog\/python-generators-tutorial\/).\n",
                ">`indices_gen = sss.split(X, y)`\n",
                "3.  Cast the variable `indices_gen` to a list and assign the **first** item in that list to the variable `indices_tuple`\n",
                "> `indices_tuple = list(indices_gen)[0]`\n",
                "4.  The first item in `indices_tuple` should be the row labels for the training set. Assign this array to the variable `train_idx`\n",
                ">`train_idx = indices_tuple[0]`\n",
                "5. The second item in `indices_tuple` should be the row labels for the testing set. Assign this array to the variable `test_idx`\n",
                ">`test_idx = indices_tuple[1]`\n",
                "\n",
                "6. Filter `X` using the row labels stored in `train_idx` and `test_idx`. Name the filtered **pandas dataframes** `X_train` and `X_test`\n",
                "\n",
                "7. Filter `y` using the row labels stored in `train_idx` and `test_idx`. Name the filtered **pandas Series** `y_train` and `y_test`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "from sklearn.model_selection import StratifiedShuffleSplit\n",
                "\n",
                "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.35, random_state=42) # keep random_state=42!\n",
                "indices_gen = None\n",
                "indices_tuple = None\n",
                "train_idx = None\n",
                "test_idx = None\n",
                "X_train, X_test = None, None\n",
                "y_train, y_test = None, None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 08",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Run the cells below to read a partially processed `X_train`, `X_test`, `y_train`, and `y_test`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "X_TRAIN_PATH = '.\/data\/X_train.csv'\n",
                "X_TEST_PATH = '.\/data\/X_test.csv'\n",
                "X_TRAIN_PREP_PATH = '.\/data\/X_train_dummies.csv'\n",
                "X_TEST_PREP_PATH = '.\/data\/X_test_dummies.csv'\n",
                "Y_TRAIN_PATH = '.\/data\/y_train.csv'\n",
                "Y_TRAIN_PREP_PATH = '.\/data\/y_train_prep.csv'\n",
                "Y_TEST_PATH = '.\/data\/y_test.csv'\n",
                "Y_TEST_PREP_PATH = '.\/data\/y_test_prep.csv'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def read_training_data(final=False):\n",
                "    if final:\n",
                "        return pd.read_csv(X_TRAIN_PREP_PATH, index_col='index').rename_axis(None)\n",
                "    else:\n",
                "        return pd.read_csv(X_TRAIN_PATH, index_col='index').rename_axis(None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def read_testing_data(final=False):\n",
                "    if final:\n",
                "        return pd.read_csv(X_TEST_PREP_PATH, index_col='index').rename_axis(None)\n",
                "    else:\n",
                "        return pd.read_csv(X_TEST_PATH, index_col='index').rename_axis(None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def read_y_train(final=False):\n",
                "    if final:\n",
                "        return pd.read_csv(Y_TRAIN_PREP_PATH, index_col='index', squeeze=True).rename_axis(None)\n",
                "    else:\n",
                "        return pd.read_csv(Y_TRAIN_PATH, index_col='index', squeeze=True).rename_axis(None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def read_y_test(final=False):\n",
                "    if final:\n",
                "        return pd.read_csv(Y_TEST_PREP_PATH, index_col='index', squeeze=True).rename_axis(None)\n",
                "    else:\n",
                "        return pd.read_csv(Y_TEST_PATH, index_col='index', squeeze=True).rename_axis(None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "X_train = read_training_data()\n",
                "X_test = read_testing_data()\n",
                "y_train = read_y_train()\n",
                "y_test = read_y_test()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 9\n",
                "\n",
                "*4 Points*\n",
                "\n",
                "The `account_balance` column in `X_train` contains missing values (stored as `np.nan`). Assign the number of missing values contained in this column as an integer to the variable `num_missing`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "num_missing = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 09",
                    "locked": true,
                    "points": "4",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's explore the numeric features. The following cell will visualize the distributions of the numeric features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "bank_renamed.hist(figsize=(14,7), layout=(2,4), bins=30);"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Note: Questions 10, 11, 12, and 13 are connected and need to be completed in sequence."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 10\n",
                "\n",
                "*5 Points*\n",
                "\n",
                "Notice the distribution above for `account_balance`. It shows that the data are skewed right. Because of this skew, we will replace the missing values in this column with the median instead of the mean.\n",
                "\n",
                "Replace all missing values in `X_train` with the median value for each column. Assign the new dataframe to the variable `X_train_nonan`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "X_train_nonan = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 10",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 11\n",
                "\n",
                "*5 Points*\n",
                "\n",
                " The `age` attribute spans from 19-87. Your next task is to write a function named `age_binner` that will discretize this feature into the following bins:\n",
                " \n",
                " - age < 20: 'teenager'\n",
                " - 20 <= age < 30: 'twenties'\n",
                " - 30 <= age < 40: 'thirties'\n",
                " - 40 <= age < 50: 'forties'\n",
                " - 50 <= age < 60: 'fifties'\n",
                " - 60 <= age: 'over-sixty'\n",
                " \n",
                "Your function should accept one parameter (int or float) and return the appropriate bin label as a string."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "def age_binner(num):\n",
                "    '''\n",
                "    Parameters:\n",
                "    num -- int or float; a number representing \n",
                "    \n",
                "    Returns: str; bin label categorizing an individual's age\n",
                "    \n",
                "    Example:\n",
                "    \n",
                "    >>> age = 31\n",
                "    >>> age_binner(age)\n",
                "    'thirties'\n",
                "    \n",
                "    '''\n",
                "    return\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 11",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Import a function `bin_ages` for the next question."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def bin_ages(num):\n",
                "        '''\n",
                "        Parameters:\n",
                "        num -- int or float; a number representing\n",
                "\n",
                "        Returns: str; bin label categorizing an individual's age\n",
                "\n",
                "        Example:\n",
                "\n",
                "        >>> age = 31\n",
                "        >>> age_binner(age)\n",
                "        'thirties'\n",
                "\n",
                "        '''\n",
                "        ###\n",
                "        ### YOUR CODE HERE\n",
                "        ###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "bin_ages(33)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 12\n",
                "\n",
                "*5 Points*\n",
                "\n",
                "Create a new column in `X_train_nonan` called `age_binned` that discretizes the `age` column into the categories defined above. Use the function `bin_ages` (imported above) to create the categories - **do not** use your function from Q11.\n",
                "\n",
                "Hint: the pandas Series method `.apply(func)` might be helpful here."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "X_train_nonan['age_binned'] = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 12",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 13\n",
                "\n",
                "*2 Points*\n",
                "\n",
                "Our training dataset is almost prepared. One of the final steps is to drop columns that won't be used in modeling. Drop all of the columns in the list `COLS_TO_DROP` from `X_train_nonan`. Assign the dataframe with the dropped columns to the variable `X_train_prepared`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "COLS_TO_DROP = ['age', 'day_of_month', 'last_contact_duration',]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "X_train_prepared = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 13",
                    "locked": true,
                    "points": "2",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For the next question, use the dataframe `q14_df` defined below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "\n",
                "        \n",
                "def partial(binner=bin_ages):\n",
                "\n",
                "    X_TRAIN_PATH = '.\/data\/X_train.csv'\n",
                "    X_TRAIN_PREP_PATH = '.\/data\/X_train_dummies.csv'\n",
                "    COLS_TO_DROP = ['age', 'day_of_month', 'last_contact_duration',]\n",
                "\n",
                "\n",
                "    def read_training_data(final=False):\n",
                "        if final:\n",
                "            return pd.read_csv(\n",
                "                        X_TRAIN_PREP_PATH,\n",
                "                        index_col='index').rename_axis(None)\n",
                "        else:\n",
                "            return pd.read_csv(\n",
                "                        X_TRAIN_PATH,\n",
                "                        index_col='index').rename_axis(None)\n",
                "\n",
                "    df = read_training_data()\n",
                "    df = df.fillna(df.median())\n",
                "    df['age_binned'] = df['age'].apply(binner)\n",
                "    df = df.drop(COLS_TO_DROP, axis=1)\n",
                "\n",
                "    return df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "q14_df = partial()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exploratory Data Analysis\n",
                "\n",
                "In this next section, we will perform exploratory data analysis. This will help us visualize the data and give us insight into relationships between the features in our dataset."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 14\n",
                "\n",
                "*8 Points*\n",
                "\n",
                "The data are nearly prepared for modeling. Let's quickly do some exploratory data analysis (EDA) before modeling. This step provides insight into potential issues and which features are good candidates for modeling.\n",
                "\n",
                " - Using the newly created `age_binned` column in `q14_df`, calculate the mean `account_balance` for each age bin.\n",
                " - Assign the means to `avg_age_balances` as a pandas Series, sorted in ascending order by the mean values. The index should be the age categories.\n",
                " \n",
                "\n",
                "Hint: [pandas.DataFrame.groupby()](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.groupby.html) may be helpful.\n",
                "\n",
                "_Remember to use the dataframe `q14_df` for this question._"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "q14_df = partial()\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "avg_age_balances = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 14",
                    "locked": true,
                    "points": "8",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 15\n",
                "\n",
                "*4 Points*\n",
                "\n",
                "Create a scatter matrix using the function from the `pandas.plotting` module (as demonstrated in lecture notebooks). Assign the output from the pandas function to `ans15`.\n",
                "\n",
                "For input, use the dataframe `q_15_data` below and set `figsize=(12,12)` and `diagonal='kde`. Leave all other parameters set to their default value.\n",
                "\n",
                "Hint: Review these [pandas docs](https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.plotting.scatter_matrix.html)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "COLS_TO_PLOT = [\n",
                "    'account_balance',\n",
                "    'num_contacts_campaign',\n",
                "    'days_since_prev_campaign',\n",
                "    'num_contacts_previous',\n",
                "]\n",
                "q_15_data = partial()[COLS_TO_PLOT]\n",
                "q_15_data.head(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "ans15 = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 15",
                    "locked": true,
                    "points": "4",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Preprocess Target Variables\n",
                "With our training data nearly prepared, we will turn our focus on the target variable `y_train`. Let's look at the distribution of clients that subscribed a term deposit."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(y_train.value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 16\n",
                "\n",
                "*8 Points*\n",
                "\n",
                "If our goal is to create classification models that predict which clients are likely to subscribe, we need to convert the values in `y_train` to be numeric instead of \"no\" and \"yes\".\n",
                "\n",
                "- Write a [lambda](https:\/\/realpython.com\/python-lambda\/) function that accepts one parameter (\"yes\" or \"no\"). Your function should return a `1` (`int`) when the value is \"yes\", otherwise return `0` (`int`). Assign the lambda function to the variable `label_encoder`.\n",
                "- Use your lambda function to create a new pandas Series with `1`'s and `0`'s. Assign this Series to `y_train_encoded`.\n",
                "\n",
                "Hint: the `.apply()` Series method may be handy for the second bullet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "label_encoder = None\n",
                "y_train_encoded = None\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 16",
                    "locked": true,
                    "points": "8",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As a final step preparing the dataset, we will create \"dummy variables\", which are numeric representations of categorical data. Some machine learning packages (i.e. `sklearn`) require all data to be numeric.\n",
                "\n",
                "Pandas provides a convenient function, `pd.get_dummies()` that will create dummy variables for all categorical columns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.get_dummies(X_train_prepared, drop_first=True).head(3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##  Linear Algebra and Ordinary Least Squares\n",
                "\n",
                "For the remaining questions, we will import a fully prepared training and testing dataset. The target variable for the regression models will be `account_balance` because it is a continuous variable.\n",
                "\n",
                "**Note:**\n",
                "We will use `statsmodels` to create the linear regression models because it offers rich diagnostic tools for regression. `scikit-learn` takes a more general purpose model building approach focused on generalization rather than diagnostics, which can be specific to regression."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train_final = read_training_data(final=True)\n",
                "y_train_final = read_y_train(final=True)\n",
                "X_test_final = read_testing_data(final=True)\n",
                "y_test_final = read_y_test(final=True)\n",
                "\n",
                "print(\"First 3 Training Samples:\")\n",
                "print(X_train_final.head(3))\n",
                "print(\"First 3 Training Labels:\")\n",
                "print(y_train_final.head(3))\n",
                "print(\"First 3 Testing Samples:\")\n",
                "print(X_test_final.head(3))\n",
                "print(\"First 3 Testing Labels:\")\n",
                "print(y_test_final.head(3))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Number of rows:\\t\\t{}\".format(X_train_final.shape[0]))\n",
                "print(\"Number of columns:\\t{}\".format(X_train_final.shape[1]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 17\n",
                "\n",
                "*10 Points*\n",
                "\n",
                "Create an [Ordinary Least Squares](https:\/\/www.statsmodels.org\/dev\/generated\/statsmodels.regression.linear_model.OLS.html) regression model using statsmodels:\n",
                "\n",
                "- Prepend a column of ones to `X_train_final` and `X_test_final` for the intercept term ([`statsmodels.api.add_constant(df)`](https:\/\/www.statsmodels.org\/stable\/generated\/statsmodels.tools.tools.add_constant.html)). Assign output to `X_train_ols` and `X_test_ols`, respectively.\n",
                "- Fit an OLS model using `X_train_ols` and `y_train_final`. Assign the model object to `ols_model`.\n",
                "- Using `ols_model`, create predictions for `X_test_ols` and assign to `ols_test_preds`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### GRADED\n",
                "import statsmodels.api as sm\n",
                "### YOUR SOLUTION HERE\n",
                "\n",
                "X_train_ols = None\n",
                "X_test_ols = None\n",
                "ols_model = None\n",
                "ols_test_preds = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 17",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 18\n",
                "\n",
                "*8 Points*\n",
                "\n",
                "The final training set has 46 columns, including dummy variables. The model above uses every one of the features in the model. Your next task will be to reduce this dimensionality.\n",
                "\n",
                "Use [PCA](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.decomposition.PCA.html) to reduce the dimensionality of `X_train_final`.\n",
                "\n",
                "- Fit a PCA instance with `X_train_final` with `random_state=24` (leave the rest as default) and assign to `pca_all`.\n",
                "- Transform `X_train_final` using the fit `pca_all` instance. Assign the result as a numpy array to `pca_components`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "from sklearn.decomposition import PCA\n",
                "### YOUR SOLUTION HERE\n",
                "pca_all = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 18",
                    "locked": true,
                    "points": "8",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 19\n",
                "\n",
                "*4 Points*\n",
                "\n",
                "After fitting an instance of [PCA](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.decomposition.PCA.html), the attribute `.explained_variance_ratio_` shows how much variance is explained from each PCA component. How many components are required to capture at least 90% of the variance contained within `X_train_final`? Assign the number as an integer or float to `ninety_percent_variance`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "\n",
                "### YOUR SOLUTION HERE\n",
                "ninety_percent_variance = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 19",
                    "locked": true,
                    "points": "4",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "\n",
                "### Question 20\n",
                "\n",
                "*10 Points*\n",
                "\n",
                "The fully prepared training and testing data is reloaded below and assigned to the following variables:\n",
                "- `X_train_final`\n",
                "- `X_test_final`\n",
                "- `y_train_final`\n",
                "- `y_test_final`\n",
                "\n",
                "For the last question, you will create another OLS model using 1 Principal Component.\n",
                "- Instantiate an instance of PCA with the following configuration and assign to `pca_one`:\n",
                "\n",
                ">`PCA(n_components=1, random_state=24)`\n",
                "\n",
                "- Using `pca_one`, fit and transform `X_train_final` and assign the output to `X_train_pca`.\n",
                "- Using `pca_one`, transform `X_test_final` and assign output to `X_test_pca` (Be careful not to refit on testing data!)\n",
                "- Create an [OLS](https:\/\/www.statsmodels.org\/dev\/generated\/statsmodels.regression.linear_model.OLS.html) regression model using statsmodels:\n",
                "    - Prepend a column of ones to `X_train_pca` and `X_test_pca` for the intercept term ([`statsmodels.api.add_constant(df)`](https:\/\/www.statsmodels.org\/stable\/generated\/statsmodels.tools.tools.add_constant.html)) \n",
                "    - Fit an OLS model using `X_train_pca` and `y_train_final`. Assign the model to `pca_model`\n",
                "    - Using `pca_model`, create predictions for `X_test_pca` and assign to `pca_test_preds`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "X_train_final = read_training_data(final=True)\n",
                "y_train_final = read_y_train(final=True)\n",
                "X_test_final = read_testing_data(final=True)\n",
                "y_test_final = read_y_test(final=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### GRADED\n",
                "import statsmodels.api as sm\n",
                "### YOUR SOLUTION HERE\n",
                "pca_one = None\n",
                "X_train_pca = None\n",
                "X_test_pca = None\n",
                "pca_model = None\n",
                "pca_preds = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Question 20",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Evaluate the model\n",
                "\n",
                "If Q17 and Q20 above are completed correctly, the following cell will output the testing root mean squared error (RMSE) for both models. Notice the similar scores, despite the fact the model fit with PCA used only 1 component.\n",
                "\n",
                "The interpretation of can be a helpful evaluation metric when comparing models because it is an absolute measure of fit and conveniently in the target variable units. The RMSE can be interpreted as the standard deviation of the unexplained error. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import mean_squared_error\n",
                "\n",
                "rmse_test_ols = np.round(np.sqrt(mean_squared_error(y_test_final, ols_test_preds)), 3)\n",
                "print(\"OLS root mean squared error (46 features):\\t{}\".format(rmse_test_ols))\n",
                "\n",
                "rmse_test_pca = np.round(np.sqrt(mean_squared_error(y_test_final, pca_test_preds)), 3)\n",
                "print(\"PCA root mean squared error (1 component):\\t{}\".format(rmse_test_pca))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Back to top](#Index:) \n",
                "<a id = \"beatles\"><\/a>\n",
                "#### Beatles data source credit\n",
                "\n",
                "> *The Beatles data was modified from [this source](https:\/\/github.com\/rmnoon\/beatles-songs), which is available with the following license and copyright notice:*\n",
                ">\n",
                ">\n",
                "> MIT License\n",
                ">\n",
                "> Copyright (c) 2016 Ryan Noon\n",
                "> \n",
                "> Permission is hereby granted, free of charge, to any person obtaining a copy\n",
                "of this software and associated documentation files (the \"Software\"), to deal\n",
                "in the Software without restriction, including without limitation the rights\n",
                "to use, copy, modify, merge, publish, distribute, sublicense, and\/or sell\n",
                "copies of the Software, and to permit persons to whom the Software is\n",
                "furnished to do so, subject to the following conditions:\n",
                "> \n",
                "> The above copyright notice and this permission notice shall be included in all\n",
                "copies or substantial portions of the Software.\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 [3.7]",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}